{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_optimized import *\n",
    "import warnings\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "warnings.simplefilter('ignore')\n",
    "total_splits = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_cb(df, take_values=True):\n",
    "    mode = lambda x: stats.mode(x).mode[0]\n",
    "    fst = lambda vec: vec.iloc[0]\n",
    "    simple_trend = lambda vec: np.sum(vec.shift(1)-vec[1:])\n",
    "    \n",
    "    num_features = ['min', 'max', 'median', 'sum', simple_trend]\n",
    "    cat_features = [unique_cnt, 'min', 'max', mode]\n",
    "   \n",
    "    res = df.groupby('id')[['first_prch_num', 'q', 'v_l', 'month', 'time_weight', 'v_l_tw']].agg({\n",
    "        'first_prch_num':'max',\n",
    "        'q':'sum',\n",
    "        'v_l':'sum',\n",
    "        'month':unique_cnt,\n",
    "        'time_weight':['min', 'median'],\n",
    "        'v_l_tw':'median'\n",
    "    })\n",
    " \n",
    "    if take_values:\n",
    "        return res.values, res.index\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_xgb(df, take_values=True):\n",
    "    mode = lambda x: stats.mode(x).mode[0]\n",
    "    fst = lambda vec: vec.iloc[0]\n",
    "    simple_trend = lambda vec: np.sum(vec.shift(1)-vec[1:])\n",
    "    \n",
    "    num_features = ['min', 'max', 'median', 'sum', simple_trend]\n",
    "    cat_features = [unique_cnt, 'min', 'max', mode]\n",
    "   \n",
    "    res = df.groupby('id')[['first_prch_num', 'q', 'v_l', 'month', 'time_weight', 'v_l_tw',\n",
    "                            'percent', 'sum_b_tw', 'q_tw', 'code_azs', 'cur_points', 'sum_b',\n",
    "                            'true_percent', 'percent_tw']].agg({\n",
    "        'first_prch_num': ['max'],\n",
    "        'percent': [simple_trend],\n",
    "        'sum_b_tw': ['median', 'max'],\n",
    "        'q_tw': ['median', 'sum'],\n",
    "        'q': [simple_trend, 'sum'],\n",
    "        'v_l': ['sum', 'max'],\n",
    "        'month': [unique_cnt, mode],\n",
    "        'time_weight': ['min', 'median'],\n",
    "        'v_l_tw': ['median'],\n",
    "        'code_azs': [mode],\n",
    "        'cur_points': [simple_trend],\n",
    "        'sum_b': ['sum'],\n",
    "        'weekday': [mode],\n",
    "        'true_percent': ['max'],\n",
    "        'percent_tw': ['sum']\n",
    "    })\n",
    " \n",
    "    if take_values:\n",
    "        return res.values, res.index\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_knn(df, take_values=False):\n",
    "    mode = lambda x: stats.mode(x).mode[0]\n",
    "    fst = lambda vec: vec.iloc[0]\n",
    "    simple_trend = lambda vec: np.sum(vec.shift(1)-vec[1:])\n",
    "   \n",
    "    num_features = ['min', 'max', 'median', 'sum', simple_trend]\n",
    "    cat_features = [unique_cnt, 'min', 'max', mode]\n",
    "   \n",
    "    res = df.groupby('id')[[ 'q_tw', 'sum_b', 'v_l_tw',\n",
    "                            'percent_tw', 'time_weight']].agg({\n",
    "        'q_tw':['sum', 'median'],\n",
    "        'v_l_tw':['sum', 'mean'],\n",
    "        'sum_b':['sum', 'mean'],\n",
    "        'time_weight':['median', 'sum']\n",
    "    })\n",
    " \n",
    "    if take_values:\n",
    "        return res.values, res.index\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Adding features..\n",
      "Aggregating..\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_tr_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-da75ffb086fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_tr_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtake_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtake_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msave_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/holdouts_xgb.hdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msave_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/holdouts_cb.hdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msave_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/holdouts_knn.hdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_tr_cat' is not defined"
     ]
    }
   ],
   "source": [
    "for offset in range(total_splits):\n",
    "    print(offset)\n",
    "    X_train, y_train = calculate_target(train, offset=offset)\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train)\n",
    "    print(\"Adding features..\")\n",
    "    X_tr, X_val = add_features(X_tr, X_val, sort=True)\n",
    "    print(\"Aggregating..\")\n",
    "#     X_tr_xgb, X_val_xgb = aggregate_xgb(X_tr, take_values=False), aggregate_xgb(X_val, take_values=False)\n",
    "    X_tr_cb, X_val_cb = aggregate_cb(X_tr, take_values=False), aggregate_cb(X_val, take_values=False)\n",
    "    X_tr_knn, X_val_knn = aggregate_knn(X_tr, take_values=False), aggregate_knn(X_val, take_values=False)\n",
    "    \n",
    "    save_split('data/holdouts_xgb.hdf', X_tr_cat, X_val_c, y_tr, y_val, str(offset))\n",
    "    save_split('data/holdouts_cb.hdf', X_tr_cb, X_val_cb, y_tr, y_val, str(offset))\n",
    "    save_split('data/holdouts_knn.hdf', X_tr_knn, X_val_knn, y_tr, y_val, str(offset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame with models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_param = {\n",
    "    'depth': 8,\n",
    "    'eval_metric': 'AUC',\n",
    "    'l2_leaf_reg': 0.01,\n",
    "    'random_seed': 42,\n",
    "    'rsm': 0.5,\n",
    "    'train_dir': './catboost',\n",
    "    'verbose': False,\n",
    "    'od_type': 'Iter'\n",
    "}\n",
    "\n",
    "cb = CatBoostClassifier(**cb_param)\n",
    "cat_features=[]\n",
    "scores_cb, probas_cb = cross_val(cb, None, None, return_proba=True, splits=total_splits,\n",
    "                           splits_file='data/holdouts_cb.hdf', verbose=True,\n",
    "                          cat_features=cat_features)\n",
    "print(np.mean(scores_cb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'booster': 'gblinear',\n",
    "    'objective': 'binary:logistic',\n",
    "    'lambda': 0.5,\n",
    "    'learning_rate': 1.2,\n",
    "    'silent': 1.0,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(**xgb_params, num_rounds = 500, n_jobs=-1)\n",
    "scores_xgb, probas_xgb = cross_val(xgb, None, None, return_proba=True, splits=total_splits,\n",
    "                                   splits_file='data/holdouts_xgb.hdf', verbose=True)\n",
    "print(np.mean(scores_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNNClassifier(200)\n",
    "scores_knn, probas_knn = cross_val(knn, None, None, return_proba=True, splits=total_splits,\n",
    "                                   splits_file='data/holdouts_knn.hdf', verbose=True)\n",
    "print(np.mean(scores_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add columns: xgb, KNN etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'cb': pd.concat(probas_cb), 'xgb': pd.concat(probas_xgb), 'knn': pd.concat(probas_knn)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = []\n",
    "for offset in range(total_splits):\n",
    "    X_tr, X_val, y_tr, y_val = load_split('data/holdouts_cb.hdf', offset)\n",
    "    target.append(y_val)\n",
    "target = pd.concat(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in X_val.columns:\n",
    "    print(col,\"-\",roc_auc_score(y_val, X_val[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = tr_val(X, target, train_size=0.75, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lgb.fit(X_tr, y_tr).predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, X_val.iloc[:, 0]), roc_auc_score(y_val, X_val.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(fit_intercept=False).fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr.fit(X_tr, y_tr).predict(X_val)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set whichever stacker you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('nov_test.pkl', 'rb') as f:\n",
    "    nov_pred = pickle.load(f)\n",
    "with open('dec_test.pkl', 'rb') as f:\n",
    "    dec_pred = pickle.load(f)\n",
    "\n",
    "X_train_nov, y_train_nov = calculate_target(train, offset=2)\n",
    "X_train_dec, y_train_dec = calculate_target(train, offset=0)\n",
    "X_train_nov.shape, y_train_nov.shape\n",
    "\n",
    "X_test_add_nov = X_test.set_index('id').loc[nov_pred].reset_index()\n",
    "X_test_add_dec = X_test.set_index('id').loc[dec_pred].reset_index()\n",
    "\n",
    "X_train_nov, X_test_add_nov = add_features(X_train_nov, X_test_add_nov, sort=True)\n",
    "X_train_dec, X_test_add_dec = add_features(X_train_dec, X_test_add_dec, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = [aggregate_knn]\n",
    "X_train_agg_nov = aggregate_new(X_train_nov, take_values=False)\n",
    "X_train_agg_dec = aggregate_new(X_train_dec, take_values=False)\n",
    "\n",
    "X_test_agg_nov = aggregate_new(X_test_add_nov, take_values=False)\n",
    "X_test_agg_dec = aggregate_new(X_test_add_dec, take_values=False)\n",
    "\n",
    "params = {\n",
    "    'depth': 8,\n",
    "    'eval_metric': 'AUC',\n",
    "    'l2_leaf_reg': 0.01,\n",
    "    'random_seed': 42,\n",
    "    'rsm': 0.5,\n",
    "    'train_dir': './catboost',\n",
    "    'verbose': False,\n",
    "    'od_type': 'Iter'\n",
    "}\n",
    "\n",
    "X_train_agg_nov.shape, y_train_nov.shape\n",
    "\n",
    "clf_nov = CatBoostClassifier(**params)\n",
    "clf_nov.fit(X_train_agg_nov.values, y_train_nov, plot=True)\n",
    "\n",
    "clf_dec = CatBoostClassifier(**params)\n",
    "clf_dec.fit(X_train_agg_dec.values, y_train_dec, plot=True)\n",
    "\n",
    "sample_submission = pd.read_csv('catboost_petr.csv', index_col='id')\n",
    "\n",
    "sample_submission.loc[nov_pred,'proba'] = clf_nov.predict_proba(X_test_agg_nov.values)[:, 1]\n",
    "sample_submission.loc[dec_pred,'proba'] = clf_dec.predict_proba(X_test_agg_dec.values)[:, 1]\n",
    "\n",
    "sample_submission.head()\n",
    "\n",
    "sample_submission.to_csv('submissions/catboost_7feats_separated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###SOME MAGIC WITH GENERATING SUBMISSIONS FROM DIFFERENT MODELS\n",
    "# suppose, now we have submission_cb, submission_lgb, submission_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('submissions/sample_submission.csv')\n",
    "submission_cb = pd.read_csv('submissions/catboost_7feats_separated.csv')\n",
    "submission_xgb = pd.read_csv('submissions/xgboost_21main_bestparam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_cb.proba = submission_cb.proba*0.8 + submission_xgb.proba*0.2\n",
    "submission_cb.to_csv('submissions/FINAL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_probas = pd.DataFrame({'cb': submission_cb.proba, 'xgb': submission_xgb.proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission.proba = clf.predict(X_test_probas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
