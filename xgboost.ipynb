{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating\n",
    "1. hd = 0.744 lb = 0.76195 agg_custom\n",
    "2. hd = 0.747 lb = 0.76741 aggregate\n",
    "3. hd = 0.756 lb = 0.78332 agg_petrovich\n",
    "4. hd = 0.746 lb = ... aggregate_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data-scientist prays like this:\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = load_data(resave=True, points=True, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = load_data(resave=False, points=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4480835, 17), (4751035, 16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = calculate_target(train, offset=0)\n",
    "X_test = test\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add aditional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4480835, 19), (4751035, 18))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm = pd.read_csv('./rfm-segments.csv')\n",
    "new_columns = rfm[['customer', 'R_Quartile', 'F_Quartile']]\n",
    "X_train = X_train.merge(new_columns, left_on='id', right_on='customer', how='left')\n",
    "X_test = X_test.merge(new_columns, left_on='id', right_on='customer', how='left')\n",
    "X_train.drop('customer', axis=1, inplace=True)\n",
    "X_test.drop('customer', axis=1, inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_tr', 'code_azs', 'location', 'region', 'code', 'code1', 'type', 'month', 'weekday', 'rich_category', 'R_Quartile', 'F_Quartile']\n"
     ]
    }
   ],
   "source": [
    "cat_features_name = get_cat_features()\n",
    "cat_features_name += ['rich_category', 'R_Quartile', 'F_Quartile']\n",
    "print(cat_features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c48bedcb9df4e938e85fa20657041aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm_notebook(X_train.columns):\n",
    "    if col in cat_features_name:\n",
    "        X_train[col].fillna('-' if col == 'code' else -99999, inplace=True)\n",
    "        X_test[col].fillna('-' if col == 'code' else -99999, inplace=True)\n",
    "        le = LabelEncoder().fit(X_train[col].append(X_test[col]))\n",
    "        X_train[col] = le.transform(X_train[col])\n",
    "        X_test[col] = le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate(df, take_values=True):\n",
    "    mode = lambda x: stats.mode(x).mode[0]\n",
    "    fst = lambda vec: vec.iloc[0]\n",
    "    simple_trend = lambda vec: np.sum(vec.shift(1)-vec[1:])\n",
    "    \n",
    "    num_features = ['min', 'max', 'median', 'sum', simple_trend]\n",
    "    cat_features = [unique_cnt, 'min', 'max', mode]\n",
    "   \n",
    "    res = df.groupby('id')[['code', 'code1', 'code_azs', 'cur_points', 'first_prch_num', 'location',\\\n",
    "                           'oil_price', 'percent', 'q', 'region', 'return_num',\\\n",
    "                           'rich_category','sum_b', 'total_user_spend',\\\n",
    "                           'type', 'user_spend_fuel', 'v_l', 'month', 'weekday', 'true_percent',\\\n",
    "                           'time_weight', 'R_Quartile', 'F_Quartile']].agg({\n",
    "        'code':[unique_cnt, mode],\n",
    "        'code1':[unique_cnt, mode],\n",
    "        'code_azs':[unique_cnt, mode],\n",
    "        'cur_points':num_features,\n",
    "        'first_prch_num':'max',\n",
    "        'location':[unique_cnt, mode],\n",
    "        'oil_price':['min', 'max'],\n",
    "        'percent': num_features,\n",
    "        'q': num_features,\n",
    "        'region':[unique_cnt, mode],\n",
    "        'return_num':'max',\n",
    "        'rich_category':'max',\n",
    "        'sum_b': num_features,\n",
    "        'total_user_spend': 'max',\n",
    "        'type':[unique_cnt, mode],\n",
    "        'user_spend_fuel':num_features,\n",
    "        'v_l':num_features,\n",
    "        'month':[unique_cnt, mode],\n",
    "        'weekday':[unique_cnt, mode],\n",
    "        'true_percent':['max', 'median'],\n",
    "        'time_weight': num_features,\n",
    "        'R_Quartile': ['median'],\n",
    "        'F_Quartile': ['median']\n",
    "    })\n",
    " \n",
    "    if take_values:\n",
    "        return res.values, res.index\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3392763, 1088072)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, train_size=0.75)\n",
    "X_tr.shape[0], X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_tr, X_val = add_features(X_tr, X_val, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to(X_tr, X_val, 'data/holdout.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_val = load_from('data/holdout.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_tr_agg, X_val_agg = aggregate(X_tr, take_values=False), aggregate(X_val, take_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to(X_tr_agg, X_val_agg, 'data/aggregate.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr_agg, X_val_agg = load_from('data/aggregate.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [col for col in X_tr_agg.columns if col in cat_features_name or \n",
    "                                        (col[0] in cat_features_name and col[1] != 'unique_cnt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39540, 1442), (39540, 50), (13181, 1442), (13181, 50))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = OneHotEncoder().fit(X_tr_agg[cat_features].append(X_val_agg[cat_features]))\n",
    "X_tr_ohe = le.transform(X_tr_agg[cat_features])\n",
    "X_val_ohe = le.transform(X_val_agg[cat_features])\n",
    "X_tr_ohe.shape, X_tr_agg.drop(cat_features, axis=1).shape, X_val_ohe.shape, X_val_agg.drop(cat_features, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39540, 1492)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_ohe = hstack([X_tr_ohe, coo_matrix(X_tr_agg.drop(cat_features, axis=1))])\n",
    "X_val_ohe = hstack([X_val_ohe, coo_matrix(X_val_agg.drop(cat_features, axis=1))])\n",
    "X_tr_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': 'gblinear',\n",
    "    'objective': 'binary:logistic',\n",
    "    'lambda': 0.1,\n",
    "    'learning_rate': 1.0,\n",
    "    'silent': 1.0,\n",
    "    'seed': 42\n",
    "}\n",
    "eval_params = params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(**eval_params, num_rounds = 500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_tr_ohe, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(X_val_ohe)[:, 1]\n",
    "roc_auc_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9477369268302286"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier(random_state=42, n_estimators=100, n_jobs=-1, verbose=1)\n",
    "rfclf.fit(X_tr_agg.values, y_tr)\n",
    "\n",
    "roc_auc_score(y_val, rfclf.predict_proba(X_val_agg.values)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    if param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = 0.75\n",
    "    clf = CatBoostClassifier(**params)\n",
    "    clf.fit(X_tr_agg.values, y_tr, cat_features=cat_features)\n",
    "    predictions = clf.predict_proba(X_val_agg.values)[:, 1]\n",
    "    score = roc_auc_score(y_val, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    \n",
    "    # 1 075 200 fits\n",
    "    space_all = {\n",
    "        'random_seed': 42,\n",
    "        'eval_metric': 'AUC',\n",
    "        'train_dir': './catboost',\n",
    "        'verbose': False,\n",
    "        \n",
    "        'iteration': hp.choice('iteration', np.linspace(10, 1000, 10)),\n",
    "        'learning_rate': hp.choice('learning_rate', np.linspace(0.001, 0.1, 10)),\n",
    "        'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'bagging_temperature': hp.choice('bagging_temperature', np.linspace(0, 1, 4)),\n",
    "        \n",
    "        'l2_leaf_reg': hp.choice('l2_leaf_reg', [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2]),\n",
    "        'depth': hp.choice('depth', np.arange(2, 16, 2)),\n",
    "        'rsm': hp.choice('rsm', np.linspace(0, 1, 4)),\n",
    "        'leaf_estimation_method': hp.choice('leaf_estimation_method', ['Newton', 'Gradient']),\n",
    "        'leaf_estimation_method': hp.choice('leaf_estimation_method', np.arange(1, 4))\n",
    "    }\n",
    "    \n",
    "    # 11 250 fits\n",
    "    space_mini = {\n",
    "        'random_seed': 42,\n",
    "        'eval_metric': 'AUC',\n",
    "        'train_dir': './catboost',\n",
    "        'verbose': False,\n",
    "        \n",
    "        'iteration': hp.choice('iteration', np.linspace(50, 1000, 5)),\n",
    "        'learning_rate': hp.choice('learning_rate', np.linspace(0.001, 0.1, 5)),\n",
    "        'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'bagging_temperature': hp.choice('bagging_temperature', np.linspace(0, 1, 3)),\n",
    "        \n",
    "        'l2_leaf_reg': hp.choice('l2_leaf_reg', [1e-3, 1e-2, 1e-1, 1e0, 1e1]),\n",
    "        'depth': hp.choice('depth', np.arange(2, 11, 2)),\n",
    "        'rsm': hp.choice('rsm', np.linspace(0, 1, 3))\n",
    "    }\n",
    "    \n",
    "    best = fmin(score, space_mini, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_params = optimize(trials)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_add, X_test_add = add_features(X_train, X_test, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_agg = aggregate(X_train_add, take_values=False)\n",
    "X_test_agg = aggregate(X_test_add, take_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(**params)\n",
    "clf.fit(X_train_agg.values, y_train, cat_features=cat_features, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_test_agg.values)[:, 0]\n",
    "y_pred = pd.Series(y_pred, index=X_test_agg.index)\n",
    "y_pred = y_pred.reindex(sample_submission.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission['proba'] = y_pred.values\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submissions/catboost_agg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
